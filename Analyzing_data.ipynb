{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries pandas \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Library?\n",
    "\n",
    "I used panda because of it's ability to manipulate data sets in just a few lines of coding.The data I loaded is MASER detecton data over hours of observation. To load the data set I first had to Import panda as pd and then I had to find the data on my computer. I assigned the variable maserdata=(to the filename of the data on my computer). Finally I decided to view the data as table by using behav.pd.read_table(maserdata, sep='\\+s', index_col='time') with time as the index to make my future data analyzing commands possible. So I wouldn't have an enormous table I told it to only view the first 8 rows by \n",
    "from pandas import set_option\n",
    "set_option('display.max_rows',8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use behav.shape to tell me the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert it to a datetime object with units of minutes \n",
    "\n",
    "#behav.index=pd.to_datetime(behav.index, unit='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take the average every 20minutes and rename this data by\n",
    "\n",
    "#behav_average=behav.resample('20m', how=('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look at new shape of data \n",
    "\n",
    "#behav_average.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to first use a function that would tell me the shape of the data set so that I could know how many points I was working with. I then converted the dataset to a datetime object with units of minutes since my original data had been collected over hours of observation but I wanted to be more percise when analyzing it.This also allowed me to perform my next function of taking 20minute time averages. I was only able to take these averages because I had set up my data as time indexed from the start and as a datetime object. It is useful for me to ultimately be able to take these avarages since I otherwise have a lot of data but the averages included in my data are on too long of a time span to get accurate points. With these shorter time-averages I have a good amount of detection points to ultimately help me zero in on the location of a detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
